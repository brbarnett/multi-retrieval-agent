{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_ENDPOINT\"],\n",
    "    deployment=os.environ[\"OPENAI_API_EMBEDDINGS_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "with open(\"./data/work_orders.json\", \"r\") as f:\n",
    "    work_orders = json.load(f)\n",
    "\n",
    "documents = [Document(page_content=json.dumps(wo)) for wo in work_orders]\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import shared dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create query tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkOrderSearch(BaseModel):\n",
    "    issue: str = Field(\n",
    "        ...,\n",
    "        description=\"Issue reported by the maintenance tech to search work orders. For example, air entrapment or incomplete curing\",\n",
    "    )\n",
    "    temporal: str = Field(\n",
    "        ...,\n",
    "        description=\"Temporal string that refers to the first or last `n` work orders. Options can be 'first', 'last' or 'all'\",\n",
    "    )\n",
    "    n: Optional[int] = Field(..., description=\"Number of work orders requested\")\n",
    "\n",
    "\n",
    "@tool(args_schema=WorkOrderSearch)\n",
    "def search_work_orders(issue: str, temporal: str, n: Optional[int] = 3) -> List:\n",
    "    \"\"\"Search for work orders where a similar issue was observed and/or resolved.\"\"\"\n",
    "\n",
    "    embedding = embeddings.embed_query(issue)\n",
    "    results = db.similarity_search_with_score_by_vector(embedding, n)\n",
    "    result_documents = [json.loads(result[0].page_content) for result in results]\n",
    "\n",
    "    if temporal == \"last\":\n",
    "        result_documents = sorted(\n",
    "            result_documents, key=lambda doc: doc[\"date\"], reverse=True\n",
    "        )\n",
    "    elif temporal == \"first\":\n",
    "        result_documents = sorted(\n",
    "            result_documents, key=lambda doc: doc[\"date\"], reverse=False\n",
    "        )\n",
    "\n",
    "    return result_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "parts = pd.read_json(\"./data/parts.json\")\n",
    "\n",
    "\n",
    "class PartsSearch(BaseModel):\n",
    "    partName: Optional[str] = Field(\n",
    "        ..., description=\"Name or description of the part and is a word or phrase\"\n",
    "    )\n",
    "    partNumber: Optional[str] = Field(\n",
    "        ..., description=\"Part number or ID. This is in the format `XX-00000`\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(args_schema=PartsSearch)\n",
    "def search_parts(partName: Optional[str], partNumber: Optional[str]) -> List:\n",
    "    \"\"\"Search for a part, including its current inventory and location.\"\"\"\n",
    "\n",
    "    df = parts\n",
    "\n",
    "    if partNumber is not None:\n",
    "        return sqldf(f\"SELECT * FROM df WHERE partNumber = '{partNumber}'\", locals())\n",
    "    elif partName is not None:\n",
    "        return sqldf(f\"SELECT * FROM df WHERE partName = '{partName}'\", locals())\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RAG bot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_bot import RagBot\n",
    "\n",
    "rag_bot = RagBot(tools=[search_parts, search_work_orders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "class Grade(BaseModel):\n",
    "    score: int = Field(..., description=\"Provide the score\")\n",
    "    explanation: str = Field(..., description=\"Explain your reasoning for the score\")\n",
    "\n",
    "\n",
    "def run_and_evaluate(query: str, expected: str, thread_id: str):\n",
    "    response = rag_bot.invoke(\n",
    "        query,\n",
    "        thread_id,\n",
    "    )\n",
    "    \n",
    "    # context = [\n",
    "    #     message.content for message in response[\"messages\"] if message.type == \"tool\"\n",
    "    # ]\n",
    "    answer = response[\"messages\"][-1].content\n",
    "\n",
    "    # source: https://smith.langchain.com/hub/langchain-ai/rag-answer-vs-reference\n",
    "    grade_prompt_answer_accuracy = ChatPromptTemplate(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. \n",
    "\n",
    "(2) Ensure that the student answer does not contain any conflicting statements.\n",
    "\n",
    "(3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of 1 means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "A score of 0 means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"QUESTION: {question}\n",
    "\n",
    "GROUND TRUTH ANSWER: {correct_answer}\n",
    "\n",
    "STUDENT ANSWER: {student_answer}\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    eval_llm = AzureChatOpenAI(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        api_version=\"2024-02-01\",\n",
    "        azure_deployment=os.environ[\"OPENAI_API_DEPLOYMENT\"],\n",
    "        azure_endpoint=os.environ[\"OPENAI_API_ENDPOINT\"],\n",
    "        streaming=False,\n",
    "        temperature=0,\n",
    "        verbose=False,\n",
    "    ).with_structured_output(Grade)\n",
    "\n",
    "    answer_grader = grade_prompt_answer_accuracy | eval_llm\n",
    "\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": query,\n",
    "            \"correct_answer\": expected,\n",
    "            \"student_answer\": answer,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"response\": answer,\n",
    "        \"score\": score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Here are the last two work orders related to excessive mold '\n",
      "             'wear:\\n'\n",
      "             '\\n'\n",
      "             '1. **Work Order ID:** ISSUE-1017\\n'\n",
      "             '   - **Date:** January 27, 2024\\n'\n",
      "             '   - **Issue:** Excessive mold wear\\n'\n",
      "             '   - **Solution:** Use high-quality mold materials and coatings. '\n",
      "             'Regularly inspect and maintain the mold. Implement a preventive '\n",
      "             'maintenance schedule to extend mold life.\\n'\n",
      "             '   - **Replaced Parts:** HE-12345, CP-44556\\n'\n",
      "             '\\n'\n",
      "             '2. **Work Order ID:** ISSUE-1013\\n'\n",
      "             '   - **Date:** January 18, 2024\\n'\n",
      "             '   - **Issue:** Mold surface damage\\n'\n",
      "             '   - **Solution:** Regularly inspect and repair any damage to '\n",
      "             'the mold surface. Use protective coatings to prevent further '\n",
      "             'damage. Replace the mold if necessary to ensure product '\n",
      "             'quality.\\n'\n",
      "             '   - **Replaced Parts:** HE-12345\\n'\n",
      "             '\\n'\n",
      "             'If you need more details or further assistance, let me know!',\n",
      " 'score': Grade(score=1, explanation=\"The student's answer accurately reflects the ground truth answer regarding the last two work orders related to excessive mold wear. Both work orders are correctly identified, including their IDs, dates, issues, solutions, and replaced parts. There are no conflicting statements, and the additional offer for further assistance does not detract from the factual accuracy of the response.\")}\n",
      "{'response': 'Here are the details for the replaced parts:\\n'\n",
      "             '\\n'\n",
      "             '1. **Part Name:** Heating Element\\n'\n",
      "             '   - **Part Number:** HE-12345\\n'\n",
      "             '   - **Inventory:** 15 units\\n'\n",
      "             '   - **Location:** Aisle 3, Shelf B\\n'\n",
      "             '\\n'\n",
      "             '2. **Part Name:** Control Panel\\n'\n",
      "             '   - **Part Number:** CP-44556\\n'\n",
      "             '   - **Inventory:** 3 units\\n'\n",
      "             '   - **Location:** Aisle 4, Shelf C\\n'\n",
      "             '\\n'\n",
      "             'If you need any more information, feel free to ask!',\n",
      " 'score': Grade(score=1, explanation=\"The student's answer accurately reflects all the details provided in the ground truth answer without any conflicting statements. It includes the correct part names, part numbers, inventory counts, and locations. Additionally, the extra offer for more information does not detract from the accuracy of the response.\")}\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from pprint import pprint\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "eval = run_and_evaluate(\n",
    "    query=\"What are the last 2 work orders that show excessive mold wear?\",\n",
    "    expected=\"\"\"Here are the last two work orders related to excessive mold wear:\n",
    "\n",
    "1. **Work Order ID:** ISSUE-1017\n",
    "   - **Date:** January 27, 2024\n",
    "   - **Issue:** Excessive mold wear\n",
    "   - **Solution:** Use high-quality mold materials and coatings. Regularly inspect and maintain the mold. Implement a preventive maintenance schedule to extend mold life.\n",
    "   - **Replaced Parts:** HE-12345, CP-44556\n",
    "\n",
    "2. **Work Order ID:** ISSUE-1013\n",
    "   - **Date:** January 18, 2024\n",
    "   - **Issue:** Mold surface damage\n",
    "   - **Solution:** Regularly inspect and repair any damage to the mold surface. Use protective coatings to prevent further damage. Replace the mold if necessary to ensure product quality.\n",
    "   - **Replaced Parts:** HE-12345\n",
    "\"\"\",\n",
    "    thread_id=thread_id,\n",
    ")\n",
    "\n",
    "pprint(eval)\n",
    "\n",
    "eval = run_and_evaluate(\n",
    "    query=\"What parts were replaced? What are their locations and inventory?\",\n",
    "    expected=\"\"\"Here are the details for the replaced parts:\n",
    "\n",
    "1. **Part Name:** Heating Element\n",
    "   - **Part Number:** HE-12345\n",
    "   - **Inventory:** 15 units\n",
    "   - **Location:** Aisle 3, Shelf B\n",
    "\n",
    "2. **Part Name:** Control Panel\n",
    "   - **Part Number:** CP-44556\n",
    "   - **Inventory:** 3 units\n",
    "   - **Location:** Aisle 4, Shelf C\n",
    "\"\"\",\n",
    "    thread_id=thread_id,\n",
    ")\n",
    "\n",
    "pprint(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
