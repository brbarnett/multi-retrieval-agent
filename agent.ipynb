{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_ENDPOINT\"],\n",
    "    deployment=os.environ[\"OPENAI_API_EMBEDDINGS_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "WORK_ORDERS = [\n",
    "    {\n",
    "        \"issue\": \"Uneven pressure distribution\",\n",
    "        \"solution\": \"Ensure the mold and platens are clean and properly aligned. Regularly calibrate the machine to maintain even pressure. Check for and replace any worn or damaged seals.\",\n",
    "        \"date\": \"2024-01-12\",\n",
    "        \"ID\": \"ISSUE-1001\",\n",
    "    },\n",
    "    {\n",
    "        \"issue\": \"Incomplete curing\",\n",
    "        \"solution\": \"Verify that the heating elements are functioning correctly and uniformly. Adjust the curing time and temperature settings according to material specifications. Regularly inspect and maintain heating elements and thermocouples.\",\n",
    "        \"date\": \"2024-02-05\",\n",
    "        \"ID\": \"ISSUE-1002\",\n",
    "    },\n",
    "    {\n",
    "        \"issue\": \"Material flash\",\n",
    "        \"solution\": \"Check mold clamping force and ensure it is adequate. Inspect the mold for wear and tear and repair or replace if necessary. Ensure proper material loading to prevent excess material overflow.\",\n",
    "        \"date\": \"2024-01-28\",\n",
    "        \"ID\": \"ISSUE-1003\",\n",
    "    },\n",
    "    {\n",
    "        \"issue\": \"Air entrapment\",\n",
    "        \"solution\": \"Implement proper venting techniques in the mold design. Use vacuum-assisted molding if necessary. Ensure the material is loaded correctly to minimize air pockets.\",\n",
    "        \"date\": \"2024-02-16\",\n",
    "        \"ID\": \"ISSUE-1004\",\n",
    "    },\n",
    "    {\n",
    "        \"issue\": \"Sticking of parts to mold\",\n",
    "        \"solution\": \"Apply an appropriate mold release agent before each cycle. Inspect and clean the mold surfaces regularly. Consider using molds with better release properties or modifying the mold design to reduce sticking.\",\n",
    "        \"date\": \"2024-03-03\",\n",
    "        \"ID\": \"ISSUE-1005\",\n",
    "    },\n",
    "]\n",
    "\n",
    "documents = [Document(page_content=json.dumps(wo)) for wo in WORK_ORDERS]\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import shared dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create query tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkOrderSearch(BaseModel):\n",
    "    issue: str = Field(\n",
    "        ...,\n",
    "        description=\"Issue reported by the maintenance tech to search work orders. For example, air entrapment or incomplete curing\",\n",
    "    )\n",
    "    temporal: str = Field(\n",
    "        ...,\n",
    "        description=\"Temporal string that refers to the first or last `n` work orders. Options can be 'first', 'last' or 'all'\",\n",
    "    )\n",
    "    n: Optional[int] = Field(..., description=\"Number of work orders requested\")\n",
    "\n",
    "\n",
    "@tool(args_schema=WorkOrderSearch)\n",
    "def search_work_orders(issue: str, temporal: str, n: Optional[int] = 3) -> List:\n",
    "    \"\"\"Search for work orders where a similar issue was observed and/or resolved.\"\"\"\n",
    "\n",
    "    embedding = embeddings.embed_query(issue)\n",
    "    results = db.similarity_search_with_score_by_vector(embedding, n)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "\n",
    "class PartsSearch(BaseModel):\n",
    "    partName: Optional[str] = (\n",
    "        Field(..., description=\"Name or description of the part\"),\n",
    "    )\n",
    "    partNumber: Optional[str] = Field(..., description=\"Part number or ID\")\n",
    "\n",
    "\n",
    "PARTS = [\n",
    "    {\n",
    "        \"partName\": \"Heating Element\",\n",
    "        \"partNumber\": \"HE-12345\",\n",
    "        \"inventory\": 15,\n",
    "        \"location\": \"Aisle 3, Shelf B\",\n",
    "    },\n",
    "    {\n",
    "        \"partName\": \"Platen\",\n",
    "        \"partNumber\": \"PL-67890\",\n",
    "        \"inventory\": 8,\n",
    "        \"location\": \"Aisle 1, Shelf D\",\n",
    "    },\n",
    "    {\n",
    "        \"partName\": \"Hydraulic Cylinder\",\n",
    "        \"partNumber\": \"HC-11223\",\n",
    "        \"inventory\": 5,\n",
    "        \"location\": \"Aisle 2, Shelf A\",\n",
    "    },\n",
    "    {\n",
    "        \"partName\": \"Control Panel\",\n",
    "        \"partNumber\": \"CP-44556\",\n",
    "        \"inventory\": 3,\n",
    "        \"location\": \"Aisle 4, Shelf C\",\n",
    "    },\n",
    "    {\n",
    "        \"partName\": \"Thermocouple\",\n",
    "        \"partNumber\": \"TC-78901\",\n",
    "        \"inventory\": 20,\n",
    "        \"location\": \"Aisle 3, Shelf F\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "@tool(args_schema=PartsSearch)\n",
    "def search_parts(partName: Optional[str], partNumber: Optional[str]) -> List:\n",
    "    \"\"\"Search for replacement parts\"\"\"\n",
    "\n",
    "    df = pd.read_json(json.dumps(PARTS))\n",
    "\n",
    "    if partNumber is not None:\n",
    "        return sqldf(f\"SELECT * FROM df WHERE partNumber = '{partNumber}'\", locals())\n",
    "    elif partName is not None:\n",
    "        return sqldf(f\"SELECT * FROM df WHERE partName = '{partName}'\", locals())\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `AgentExecutor` to query data using tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "tools = [search_parts, search_work_orders]\n",
    "functions = [convert_to_openai_function(f) for f in tools]\n",
    "model = AzureChatOpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_deployment=os.environ[\"OPENAI_API_DEPLOYMENT\"],\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_ENDPOINT\"],\n",
    "    temperature=0,\n",
    ").bind(functions=functions)\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "system_prompt = \"\"\"You are a helpful manufacturing assistant that has access to multiple data sources at a manufacturing facility.\n",
    "ONLY answer questions relevant in a manufacturing context.\n",
    "Answer user questions using ONLY the provided context. Do not make up any information, and if you cannot answer the question using the context, say you don't know.\n",
    "If the answer to the question can be found in chat history, simply answer the question and do not make any function calls.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "qa = AgentExecutor(agent=chain, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with conversational agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()\n",
    "\n",
    "qa.invoke(\n",
    "    {\n",
    "        \"input\": \"What are the first 2 work orders that address uneven pressure distribution?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "qa.invoke({\"input\": \"What were the solutions of those work orders?\"})\n",
    "\n",
    "qa.invoke({\"input\": \"Where would I find a Hydraulic Cylinder?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
